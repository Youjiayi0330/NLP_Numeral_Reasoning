{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.colors import LinearSegmentedColormap"
      ],
      "metadata": {
        "id": "RZdYwXOR5YHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6pbvDwI1s1U"
      },
      "outputs": [],
      "source": [
        "# Translate dataset to 'prompt-completion' format\n",
        "with open('./json_file/NQuAD_final_train_7.5k.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "prompt_completion_pairs = []\n",
        "for item in data:\n",
        "    # Construct prompt\n",
        "    prompt = f\"{item['context']} 请从以下四个选项中选择最能概括文章的句子，请考虑句子中数字的准确性。选项：A) {item['ans0']} B) {item['ans1']} C) {item['ans2']} D) {item['ans3']}\n",
        "    # Translate (0, 1, 2, 3) to (A, B, C, D)\n",
        "    completion = chr(65 + item['ans'])\n",
        "    # Add converted data to the prompt list\n",
        "    prompt_completion_pairs.append({\n",
        "        \"prompt\": prompt,\n",
        "        \"completion\": completion\n",
        "    })\n",
        "# Write to jsonl file with UTF-8 encoding and ensure_ascii=False\n",
        "with open('./json_file/prompt_completion_data.jsonl', 'w', encoding='utf-8') as f:\n",
        "    for pair in prompt_completion_pairs:\n",
        "        # Ensure that JSON dumps does not escape non-ASCII characters\n",
        "        f.write(json.dumps(pair, ensure_ascii=False) + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use OpenAI CLI to adjust dataset format(run in terminal)\n",
        "openai tools fine_tunes.prepare_data -f <LOCAL_FILE>"
      ],
      "metadata": {
        "id": "uxyz75gY3XMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload json file to OpenAI Server and get model ID(run in terminal)\n",
        "openai api files.create -f <FILE_PATH> -p purpose"
      ],
      "metadata": {
        "id": "gw069OYW3lNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune GPT model\n",
        "openai.api_key = 'sk-6i*******co5'\n",
        "openai.FineTuningJob.create(training_file=\"file-qmcjU4tOYcmzjoHk7bfWlxX3\", model=\"babbage-002\")"
      ],
      "metadata": {
        "id": "FktOT3vU2kRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "def get_answer(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        model=\"ft:babbage-002:personal::9KZIZQyg\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=1\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "correct_count = 0\n",
        "total_count = 0\n",
        "pred_list = []\n",
        "true_list = []\n",
        "with open('./json_file/prompt_completion_data_test.jsonl', 'r') as file:\n",
        "    for line in file:\n",
        "        if total_count >= 1000:\n",
        "          break\n",
        "        data = json.loads(line)\n",
        "        prompt = data['prompt']\n",
        "        true_response = data['completion']\n",
        "        pred = get_answer(prompt)\n",
        "        true_list.append(true_response)\n",
        "        pred_list.append(pred)\n",
        "        if pred == true_response:\n",
        "            print(f\"{total_count}: true\")\n",
        "            correct_count += 1\n",
        "        else:\n",
        "            print(f\"{total_count}: false\")\n",
        "        total_count +=\n",
        "accuracy = correct_count / total_count\n",
        "print(f\"Accuracy: {accuracy:.2%}\")\n",
        "with open('results.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['True Response', 'Predicted Response'])\n",
        "    for true, pred in zip(true_list, pred_list):\n",
        "        writer.writerow([true, pred])"
      ],
      "metadata": {
        "id": "4HGyL0tc4RHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Error analysis\n",
        "def convert_to_float(value):\n",
        "    try:\n",
        "        return float(value.replace(',', ''))\n",
        "    except ValueError:\n",
        "        print(f\"Error converting '{value}' to float.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def calculate_value_diff():\n",
        "    with open('answer_options.json', 'r') as file:\n",
        "        answer_options = json.load(file)\n",
        "\n",
        "    index_map = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
        "\n",
        "    differences = []\n",
        "    with open('results.csv', 'r') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for index, row in enumerate(reader):\n",
        "            if index < len(answer_options):\n",
        "                print(row)\n",
        "                correct_index = index_map[row['true']]\n",
        "                if row['pred'] in index_map:\n",
        "                    predicted_index = index_map[row['pred']]\n",
        "                else:\n",
        "                    predicted_index = -1\n",
        "                if predicted_index < 0:\n",
        "                    predicted_value = 0\n",
        "                else:\n",
        "                    predicted_value = convert_to_float(answer_options[index][predicted_index])\n",
        "                correct_value = convert_to_float(answer_options[index][correct_index])\n",
        "\n",
        "                if correct_value != predicted_value:\n",
        "                    difference = abs(predicted_value - correct_value)\n",
        "                    differences.append(difference)\n",
        "\n",
        "    return differences\n",
        "\n",
        "\n",
        "def draw_graphic(differences):\n",
        "    bins = np.arange(0, 10, 1)\n",
        "\n",
        "    n, bins, patches = plt.hist(differences, bins=bins, edgecolor=None)\n",
        "\n",
        "    # colors = [\"#00441b\", \"#006d2c\", \"#238b45\", \"#41ab5d\", \"#74c476\", \"#a1d99b\", \"#c7e9c0\", \"#e5f5e0\"]\n",
        "    colors = [\"#e5f5e0\", \"#c7e9c0\", \"#a1d99b\", \"#74c476\", \"#41ab5d\", \"#238b45\", \"#006d2c\", \"#00441b\"]\n",
        "    cmap = LinearSegmentedColormap.from_list(\"custom_green\", colors, N=len(patches))\n",
        "\n",
        "    max_height = max(n)\n",
        "    min_height = min(n)\n",
        "    for patch, height in zip(patches, n):\n",
        "        frac = (height - min_height) / (max_height - min_height)\n",
        "        color = cmap(frac)\n",
        "        patch.set_facecolor(color)\n",
        "\n",
        "    plt.title('Histogram of Numerical Data')\n",
        "    plt.xlabel('Value Diff')\n",
        "    plt.ylabel('Frequency')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "differences = calculate_value_diff()\n",
        "draw_graphic(differences)"
      ],
      "metadata": {
        "id": "HnEWjD2d4t4B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}